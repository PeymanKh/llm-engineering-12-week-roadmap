{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-29T17:38:20.888369Z",
     "start_time": "2025-09-29T17:38:19.992970Z"
    }
   },
   "source": [
    "# Import libraries\n",
    "from pydantic import BaseModel, Field\n",
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from codes.config.config import config\n",
    "\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "# Inspect the tool calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# Initialize the spy\n",
    "spy = Spy()\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(api_key=config.openai_api_key.get_secret_value(), model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 20:38:20,661 - root - INFO - Configuration loaded for environment: development\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:39:07.884552Z",
     "start_time": "2025-09-29T17:39:05.744723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm peyman.\"),\n",
    "                AIMessage(content=\"Nice to meet you, Peyman.\"),\n",
    "                HumanMessage(content=\"I am an AI engineering student, In love with agent development.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ],
   "id": "e72a12e59df8b616",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 20:39:05,787 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-338405cc-57ab-43a4-8daa-a534f369c9cd', 'json_data': {'messages': [{'content': 'Extract memories from the following conversation:', 'role': 'system'}, {'content': \"Hi, I'm peyman.\", 'role': 'user'}, {'content': 'Nice to meet you, Peyman.', 'role': 'assistant'}, {'content': 'I am an AI engineering student, In love with agent development.', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Memory'}}, 'tools': [{'type': 'function', 'function': {'name': 'Memory', 'description': None, 'parameters': {'properties': {'content': {'description': 'The main content of the memory. For example: User expressed interest in learning about French.', 'title': 'Content', 'type': 'string'}}, 'required': ['content'], 'title': 'Memory', 'type': 'object'}}}]}}\n",
      "2025-09-29 20:39:05,789 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 20:39:05,790 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-09-29 20:39:05,827 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x112a69760>\n",
      "2025-09-29 20:39:05,829 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108275150> server_hostname='api.openai.com' timeout=None\n",
      "2025-09-29 20:39:05,846 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x112a1bf80>\n",
      "2025-09-29 20:39:05,847 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 20:39:05,848 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 20:39:05,848 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 20:39:05,849 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 20:39:05,849 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 20:39:07,832 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 17:39:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'735'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1007'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999957'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_e7b34e94520c479a887695f31db43127'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=B9zdoj7cQylk_8GDwZnZ4qN462w5bdx.n6K652IfN9c-1759167547-1.0.1.1-xTw39E54W9T7HtnLw38sADDIaiOxOgpcP7vyUqmcxY2dhVX2NEZyfQdbyjOLbOtxqrDdyLkyXocU4znT5KgT41O8GP.ojhKgNCUuDI8.IjY; path=/; expires=Mon, 29-Sep-25 18:09:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=mudrzilIQUno6Iy8kxdBovZeoyVdBe07RAQIClT7Dtc-1759167547860-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986d420a4ecfd61f-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 20:39:07,839 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 20:39:07,842 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 20:39:07,845 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 20:39:07,845 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 20:39:07,846 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 20:39:07,847 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 29 Sep 2025 17:39:07 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jcfkn8uqxwulfm4co4jmz4qq'), ('openai-processing-ms', '735'), ('openai-project', 'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1007'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '30000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '29999957'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_e7b34e94520c479a887695f31db43127'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=B9zdoj7cQylk_8GDwZnZ4qN462w5bdx.n6K652IfN9c-1759167547-1.0.1.1-xTw39E54W9T7HtnLw38sADDIaiOxOgpcP7vyUqmcxY2dhVX2NEZyfQdbyjOLbOtxqrDdyLkyXocU4znT5KgT41O8GP.ojhKgNCUuDI8.IjY; path=/; expires=Mon, 29-Sep-25 18:09:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=mudrzilIQUno6Iy8kxdBovZeoyVdBe07RAQIClT7Dtc-1759167547860-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '986d420a4ecfd61f-IST'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 20:39:07,848 - openai._base_client - DEBUG - request_id: req_e7b34e94520c479a887695f31db43127\n",
      "2025-09-29 20:39:07,868 - langsmith.utils - DEBUG - LangSmith tracing is not enabled, returning original function.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:39:18.652977Z",
     "start_time": "2025-09-29T17:39:18.646513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ],
   "id": "f5ef8cc61df9eede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_jf2ulpuJlOJkopJO4KSzdlVK)\n",
      " Call ID: call_jf2ulpuJlOJkopJO4KSzdlVK\n",
      "  Args:\n",
      "    content: Peyman is an AI engineering student who loves agent development.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:39:30.866255Z",
     "start_time": "2025-09-29T17:39:30.857907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Metadata contains the tool call\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ],
   "id": "e1bb1b617f6f6d97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_jf2ulpuJlOJkopJO4KSzdlVK'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:39:43.771876Z",
     "start_time": "2025-09-29T17:39:43.756263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"),\n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),\n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ],
   "id": "65fd9e3e87e0ee8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Peyman is an AI engineering student who loves agent development.'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:40:07.675656Z",
     "start_time": "2025-09-29T17:40:01.463878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
    "                                                        \"existing\": existing_memories})"
   ],
   "id": "e093dd890ac01b46",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 20:40:01,500 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-bb4287b9-02c2-432c-826a-5e8721e9e46f', 'json_data': {'messages': [{'content': 'Generate JSONPatches to update the existing schema instances. If you need to extract or insert *new* instances of the schemas, call the relevant function(s).\\n<existing>\\n<instance id=0 schema_type=\"Memory\">\\n{\\'content\\': \\'Peyman is an AI engineering student who loves agent development.\\'}\\n</instance>\\n</existing>\\n', 'role': 'system'}, {'content': \"That's great, did you do after?\", 'role': 'assistant'}, {'content': 'I went to Tartine and ate a croissant.', 'role': 'user'}, {'content': 'What else is on your mind?', 'role': 'assistant'}, {'content': 'I was thinking about my Japan, and going back this winter!', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'temperature': 0.0, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'PatchDoc', 'description': 'Respond with JSONPatch operations to update the existing JSON document based on the provided text and schema.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the document you are patching.', 'type': 'string'}, 'planned_edits': {'description': \"Seconds, think step-by-step, reasoning over each required update and the corresponding JSONPatch operation to accomplish it. Cite the fields in the JSONSchema you referenced in developing this plan. Address each path as a group; don't switch between paths.\\n Plan your patches in the following order:1. replace - this keeps collection size the same.\\n2. remove - BE CAREFUL ABOUT ORDER OF OPERATIONS. Each operation is applied sequentially. For arrays, remove the highest indexed value first to avoid shifting indices. This ensures subsequent remove operations remain valid.\\n 3. add (for arrays, use /- to efficiently append to end).\", 'type': 'string'}, 'patches': {'description': \"Finally, provide a list of JSONPatch operations to be applied to the previous tool call's response arguments. If none are required, return an empty list. This field is REQUIRED. Multiple patches in the list are applied sequentially in the order provided, with each patch building upon the result of the previous one. Take care to respect array bounds. Order patches as follows:\\n 1. replace - this keeps collection size the same\\n 2. remove - BE CAREFUL about order of operations. For arrays, remove the highest indexed value first to avoid shifting indices.\\n 3. add - for arrays, use /- to efficiently append to end.\", 'items': {'description': \"A JSON Patch document represents an operation to be performed on a JSON document.\\n\\nNote that the op and path are ALWAYS required. Value is required for ALL operations except 'remove'.\", 'examples': [{'op': 'replace', 'path': '/path/to/my_array/1', 'value': 'the newer value to be patched'}, {'op': 'replace', 'path': '/path/to/broken_object', 'value': {'new': 'object'}}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['some', 'values']}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['newer']}, {'op': 'remove', 'path': '/path/to/my_array/1'}], 'properties': {'op': {'description': \"The operation to be performed. Must be one of 'add', 'remove', 'replace'.\", 'enum': ['add', 'remove', 'replace'], 'type': 'string'}, 'path': {'description': 'A JSON Pointer path that references a location within the target document where the operation is performed. Note: patches are applied sequentially. If you remove a value, the collection size changes before the next patch is applied.', 'type': 'string'}, 'value': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}], 'description': \"The value to be used within the operation. REQUIRED for 'add', 'replace', and 'test' operations. Pay close attention to the json schema to ensure patched document will be valid.\"}}, 'required': ['op', 'path', 'value'], 'type': 'object'}, 'type': 'array'}}, 'required': ['json_doc_id', 'planned_edits', 'patches'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Memory', 'description': '', 'parameters': {'properties': {'content': {'description': 'The main content of the memory. For example: User expressed interest in learning about French.', 'type': 'string'}}, 'required': ['content'], 'type': 'object'}}}]}}\n",
      "2025-09-29 20:40:01,503 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 20:40:01,504 - httpcore.connection - DEBUG - close.started\n",
      "2025-09-29 20:40:01,505 - httpcore.connection - DEBUG - close.complete\n",
      "2025-09-29 20:40:01,506 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-09-29 20:40:01,537 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10d1d0860>\n",
      "2025-09-29 20:40:01,537 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108275150> server_hostname='api.openai.com' timeout=None\n",
      "2025-09-29 20:40:01,553 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1329a39e0>\n",
      "2025-09-29 20:40:01,554 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 20:40:01,555 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 20:40:01,555 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 20:40:01,555 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 20:40:01,555 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 20:40:07,640 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 17:40:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'5014'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5292'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999878'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_c57cda163290424a9cd2f374bc92f9fe'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986d43667dcc4bb2-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 20:40:07,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 20:40:07,649 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 20:40:07,651 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 20:40:07,652 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 20:40:07,652 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 20:40:07,653 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 17:40:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '5014', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5292', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999878', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_c57cda163290424a9cd2f374bc92f9fe', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986d43667dcc4bb2-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 20:40:07,654 - openai._base_client - DEBUG - request_id: req_c57cda163290424a9cd2f374bc92f9fe\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:40:08.341453Z",
     "start_time": "2025-09-29T17:40:08.337879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Metadata contains the tool call\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)\n"
   ],
   "id": "f9582bcc5b6910a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_DsGEudb8dZZ6ALTujm0zBLJO', 'json_doc_id': '0'}\n",
      "{'id': 'call_OoGspfcgrTbRt8CJBActfWGM'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:40:20.607390Z",
     "start_time": "2025-09-29T17:40:20.599276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ],
   "id": "3cf108e7bd109cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Peyman is an AI engineering student who loves agent development. Recently, he went to Tartine and ate a croissant. He is also thinking about going back to Japan this winter.'\n",
      "content='Peyman went to Tartine and ate a croissant. He is also thinking about going back to Japan this winter.'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T17:40:51.582225Z",
     "start_time": "2025-09-29T17:40:51.571665Z"
    }
   },
   "cell_type": "code",
   "source": "spy.called_tools",
   "id": "9655313fa8c93674",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'PatchDoc',\n",
       "   'args': {'json_doc_id': '0',\n",
       "    'planned_edits': \"1. Add a new memory about the user going to Tartine and eating a croissant. This will be added to the existing memory content.\\n2. Add another memory about the user's thoughts on going back to Japan this winter.\",\n",
       "    'patches': [{'op': 'replace',\n",
       "      'path': '/content',\n",
       "      'value': 'Peyman is an AI engineering student who loves agent development. Recently, he went to Tartine and ate a croissant. He is also thinking about going back to Japan this winter.'}]},\n",
       "   'id': 'call_DsGEudb8dZZ6ALTujm0zBLJO',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'Peyman went to Tartine and ate a croissant. He is also thinking about going back to Japan this winter.'},\n",
       "   'id': 'call_OoGspfcgrTbRt8CJBActfWGM',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba2a5a30f367f3a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

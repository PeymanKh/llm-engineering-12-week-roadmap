{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LangGraph Memory\n",
    "\n",
    "Memory is a system that remembers information about previous interactions. For AI agents memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences.\n",
    "\n",
    "# Memory Based on Scope\n",
    "1. **Short-Term Memory (Thread-Scope):** It tracks the ongoing interactions by maintaining message history. LangGraph manages short-term memory as a part of the agent's state. state is written to a database using `checkpointer` so the thread can be resumed at any time. short-term memory updates when the graph is invoked or a step(node) is completed.\n",
    "2. **Long-Term Memory (Across Threads):** It stores user-specific or application-level data across different sessions and is shared across conversational threads. Memories are scoped to any custom `namespace`, not just within a single `thread_id`. LangGraph provides `store` to let us save and recall long-term memories."
   ],
   "id": "dce2d736e81654d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1. Short-Term Memory (Checkpoints/Persistence):\n",
    "Short-term memory operates within individual conversation thread. It saves a snapshot of the graph at each step.\n",
    "\n",
    "Key components are:\n",
    "- **Threads:** A thread is a unique identifier that groups related checkpoints(snapshots) together.\n",
    "- **StateSnapshot:** The actual checkpoint object that contains the graph state at a specific point in time.\n",
    "\n",
    "Use cases are:\n",
    "- **Conversation History:** Maintain chat context within a session.\n",
    "- **Human-in-the-Loop:** Allowing human to inspect and modify state.\n",
    "- **Time Travel:** Replaying or forking execution from specific points.\n",
    "- **Fault Tolerance:** Resuming from the last successful step after failures\n",
    "- **State Management:** Preserving intermediate results and artifacts\n",
    "\n",
    "### Example"
   ],
   "id": "510bde20f0059c8e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:23.927834Z",
     "start_time": "2025-09-29T16:28:23.530756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "def node_1(state: State) -> State:\n",
    "    return {\"answer\": \"bye\"}\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"node_1\", node_1)\n",
    "workflow.add_edge(START, \"node_1\")\n",
    "workflow.add_edge(\"node_1\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Each invocation must specify a thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
    "graph.invoke({\"question\": \"Hello\"}, config)"
   ],
   "id": "6337b13841571299",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Hello', 'answer': 'bye'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:23.934532Z",
     "start_time": "2025-09-29T16:28:23.932318Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config)",
   "id": "f9d508fcfb02cdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'question': 'Hello', 'answer': 'bye'}, next=(), config={'configurable': {'thread_id': 'conversation_1', 'checkpoint_ns': '', 'checkpoint_id': '1f09d515-1d42-6326-8001-8668505be8ac'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-29T16:28:23.925426+00:00', parent_config={'configurable': {'thread_id': 'conversation_1', 'checkpoint_ns': '', 'checkpoint_id': '1f09d515-1d41-66f6-8000-38fd5fe0e21d'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 2. Long-Term Memory (store):\n",
    "Long-Term memory allows system to retain information across different conversations or sessions. instead of `thread`, long-term memory is saved with in a `namespace`.\n",
    "\n",
    "### Long-Term Memory Types\n",
    "1. **Semantic (Facts):** Facts about the user.\n",
    "2. **Episodic (Experiences):** Past agent actions.\n",
    "3. **Procedural (Rules):** Agent's system prompt.\n",
    "\n",
    "### Semantic Memory:\n",
    "This memory is often used to store user-specific information to personalize the agent's behavior by remembering facts and concepts from the past interactions. Semantic memory is managed in different ways; it can be a single, continuously updated key-value pair(`profile`) just like JSON.\n",
    "\n",
    "### Episodic Memory:\n",
    "Facts can be written to semantic memory, whereas experiences can be written to episodic memory. It is often used to help the agent remember how to accomplish a task.\n",
    "\n",
    "### Procedural Memory:\n",
    "It is used to remember the rules used to perform a task. For AI agents, procedural memory is a combination of model weights, agent code, and agent's prompt that collectively determine the agent's functionality.\n",
    "\n",
    "In practice, it is fairly uncommon for agents to modify their model weights or rewrite their code. However, it is more common for agents to modify their own prompts.\n",
    "\n",
    "\n",
    "\n",
    "### Example"
   ],
   "id": "25590ee165278f73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LangGraph stores memories as JSON document organized using two key concepts:\n",
    "1. Namespace: A tuple that acts as a folder structure for organizing related memories. `(\"peyman_kh\", \"profile\")`\n",
    "2. Key: A unique identifier for a memory, just like a filename."
   ],
   "id": "14beb37129dc0c46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:23.948922Z",
     "start_time": "2025-09-29T16:28:23.946109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import library\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Namespace (similar to directory)\n",
    "user_id = \"user_123\"\n",
    "namespace = (user_id, \"profile\")  #/user_123/profile\n",
    "\n",
    "# Key (similar to filename)\n",
    "key = \"user_profile\"\n",
    "\n",
    "# Value (similar to file content)\n",
    "value = {\n",
    "    \"name\": \"Peyman Kh\",\n",
    "    \"age\": 30,\n",
    "    \"interests\": [\"travel\", \"cooking\", \"reading\"]\n",
    "}\n",
    "\n",
    "# Save to memory\n",
    "store = InMemoryStore()\n",
    "store.put(namespace, key, value)"
   ],
   "id": "8a926ceefecbed06",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:23.963373Z",
     "start_time": "2025-09-29T16:28:23.959700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read from memory\n",
    "store.get(namespace, key)"
   ],
   "id": "54ec7e2547ae63c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['user_123', 'profile'], key='user_profile', value={'name': 'Peyman Kh', 'age': 30, 'interests': ['travel', 'cooking', 'reading']}, created_at='2025-09-29T16:28:23.947994+00:00', updated_at='2025-09-29T16:28:23.947997+00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Trustcall\n",
    "\n",
    "When we want to update memory, two major problems might happen:\n",
    "1. When the memory schema is complex, LLM might give a validation error.\n",
    "2. If we rewrite memory everytime, we might miss context.\n",
    "\n",
    "That is the motivation behind Trustcall open-source library."
   ],
   "id": "d9c24d455eb6bb9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:32.798064Z",
     "start_time": "2025-09-29T16:28:23.971054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from codes.config.config import config\n",
    "\n",
    "# Create memory schema\n",
    "class UserProfile(BaseModel):\n",
    "    name: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The name of the user.\"\n",
    "    )\n",
    "    age: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"The age of the user.\"\n",
    "    )\n",
    "    gender: Optional[str] = Field(\n",
    "        None,\n",
    "    ),\n",
    "    interests: Optional[list[str]] = Field(\n",
    "        None,\n",
    "        description=\"The user's interests.\"\n",
    "    )\n",
    "\n",
    "# Create ChatModel instance\n",
    "llm = ChatOpenAI(api_key=config.openai_api_key.get_secret_value(), model=\"gpt-4o\")\n",
    "\n",
    "# Create trustcall executor instead of llm.with_structured_output()\n",
    "extractor = create_extractor(\n",
    "    llm,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\"\n",
    ")\n",
    "\n",
    "result = extractor.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"I'm Peyman, 27, love coding and gaming\"}]\n",
    "})"
   ],
   "id": "c01a1b6daa5294ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:28:24,257 - root - INFO - Configuration loaded for environment: development\n",
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "2025-09-29 19:28:24,499 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-dceb1e87-a09e-440e-b42a-30455c946756', 'json_data': {'messages': [{'content': \"I'm Peyman, 27, love coding and gaming\", 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': {'type': 'function', 'function': {'name': 'UserProfile'}}, 'tools': [{'type': 'function', 'function': {'name': 'UserProfile', 'description': None, 'parameters': {'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'The name of the user.', 'title': 'Name'}, 'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'description': 'The age of the user.', 'title': 'Age'}, 'gender': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Gender'}, 'interests': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'description': \"The user's interests.\", 'title': 'Interests'}}, 'title': 'UserProfile', 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:24,500 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:24,500 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-09-29 19:28:24,523 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108f72120>\n",
      "2025-09-29 19:28:24,524 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b2cb50> server_hostname='api.openai.com' timeout=None\n",
      "2025-09-29 19:28:24,538 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108d79820>\n",
      "2025-09-29 19:28:24,538 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:24,539 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:24,539 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:24,540 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:24,540 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:25,931 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'553'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'732'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999988'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_4352de376e5841b983ab66149fc5c43b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=czwVnVUuBI_5KjigcyQAdmgUzbQsTyAVg58Z5C1frXA-1759163305-1.0.1.1-uxPbmZrM4F3fkq2D8FzDzXjoEIozHNn1VVPYM6JnMtfNLVsHKXQOOqn76WIx.DxXnJOOxt5DZkzNrIJLCCWhKP.uVlEEX47XbvO3_44gNzw; path=/; expires=Mon, 29-Sep-25 16:58:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4lY2w5nHI3ZGni0RKzgEu3khecUAf6b1hnoSrpHpwg4-1759163305942-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cda7deb63f182-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:25,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:25,935 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:25,937 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:25,940 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:25,942 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:25,943 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 29 Sep 2025 16:28:25 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jcfkn8uqxwulfm4co4jmz4qq'), ('openai-processing-ms', '553'), ('openai-project', 'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '732'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '30000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '29999988'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_4352de376e5841b983ab66149fc5c43b'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=czwVnVUuBI_5KjigcyQAdmgUzbQsTyAVg58Z5C1frXA-1759163305-1.0.1.1-uxPbmZrM4F3fkq2D8FzDzXjoEIozHNn1VVPYM6JnMtfNLVsHKXQOOqn76WIx.DxXnJOOxt5DZkzNrIJLCCWhKP.uVlEEX47XbvO3_44gNzw; path=/; expires=Mon, 29-Sep-25 16:58:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4lY2w5nHI3ZGni0RKzgEu3khecUAf6b1hnoSrpHpwg4-1759163305942-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '986cda7deb63f182-IST'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:25,945 - openai._base_client - DEBUG - request_id: req_4352de376e5841b983ab66149fc5c43b\n",
      "2025-09-29 19:28:25,956 - langsmith.utils - DEBUG - LangSmith tracing is not enabled, returning original function.\n",
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "2025-09-29 19:28:25,963 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-c7a862cc-1776-4193-9761-2962ee7dab17', 'json_data': {'messages': [{'content': \"I'm Peyman, 27, love coding and gaming\", 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_oMBBpxG56Yry0qF9FzkyQac6', 'function': {'name': 'UserProfile', 'arguments': '{\"name\": \"Peyman\", \"age\": 27, \"interests\": [\"coding\", \"gaming\"]}'}}]}, {'content': 'Error:\\n\\n```\\nUnable to serialize unknown type: <class \\'pydantic.fields.FieldInfo\\'>\\n```\\nExpected Parameter Schema:\\n\\n```json\\n{\\'properties\\': {\\'name\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \\'The name of the user.\\', \\'title\\': \\'Name\\'}, \\'age\\': {\\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \\'The age of the user.\\', \\'title\\': \\'Age\\'}, \\'gender\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'title\\': \\'Gender\\'}, \\'interests\\': {\\'anyOf\\': [{\\'items\\': {\\'type\\': \\'string\\'}, \\'type\\': \\'array\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \"The user\\'s interests.\", \\'title\\': \\'Interests\\'}}, \\'title\\': \\'UserProfile\\', \\'type\\': \\'object\\'}\\n```\\nPlease use PatchFunctionErrors to fix all validation errors. for json_doc_id=[call_oMBBpxG56Yry0qF9FzkyQac6].', 'role': 'tool', 'tool_call_id': 'call_oMBBpxG56Yry0qF9FzkyQac6'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'PatchFunctionErrors', 'description': 'Respond with all JSONPatch operations required to update the previous invalid function call.\\n\\nUse to correct all validation errors in non-compliant function calls, or to extend or update existing structured data in the presence of new information. Closely analyze\\nthe parameters from the original JSONSchema to ensure the patched document will be valid\\nand that you avoid repeating the same errors.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the function you are patching.', 'type': 'string'}, 'planned_edits': {'description': 'Second, write a bullet-point list of each ValidationError you encountered and the corresponding JSONPatch operation needed to heal it. For each operation, write why your initial guess was incorrect,  citing the corresponding types(s) from the JSONSchema that will be used the validate the resultant patched document.  Think step-by-step to ensure no error is overlooked.', 'type': 'string'}, 'patches': {'description': \"Finally, provide a list of JSONPatch operations to be applied to the previous tool call's response arguments. If none are required, return an empty list. This field is REQUIRED. Multiple patches in the list are applied sequentially in the order provided, with each patch building upon the result of the previous one.\", 'items': {'description': \"A JSON Patch document represents an operation to be performed on a JSON document.\\n\\nNote that the op and path are ALWAYS required. Value is required for ALL operations except 'remove'.\", 'examples': [{'op': 'replace', 'path': '/path/to/my_array/1', 'value': 'the newer value to be patched'}, {'op': 'replace', 'path': '/path/to/broken_object', 'value': {'new': 'object'}}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['some', 'values']}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['newer']}, {'op': 'remove', 'path': '/path/to/my_array/1'}], 'properties': {'op': {'description': \"The operation to be performed. Must be one of 'add', 'remove', 'replace'.\", 'enum': ['add', 'remove', 'replace'], 'type': 'string'}, 'path': {'description': 'A JSON Pointer path that references a location within the target document where the operation is performed. Note: patches are applied sequentially. If you remove a value, the collection size changes before the next patch is applied.', 'type': 'string'}, 'value': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}], 'description': \"The value to be used within the operation. REQUIRED for 'add', 'replace', and 'test' operations. Pay close attention to the json schema to ensure patched document will be valid.\"}}, 'required': ['op', 'path', 'value'], 'type': 'object'}, 'type': 'array'}}, 'required': ['json_doc_id', 'planned_edits', 'patches'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'PatchFunctionName', 'description': 'Call this if the tool message indicates that you previously invoked an invalid tool, (e.g., \"Unrecognized tool name\" error), do so here.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the function you are patching.', 'type': 'string'}, 'reasoning': {'description': 'Seconds, provide at least 2 logical reasons why this action ought to be taken.Cite the specific error(s) mentioned to motivate the fix.', 'items': {'type': 'string'}, 'type': 'array'}, 'fixed_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Finally, if you need to change the name of the function (e.g., from an \"Unrecognized tool name\" error), do so here. Must be one of UserProfile'}}, 'required': ['json_doc_id', 'reasoning', 'fixed_name'], 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:25,964 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:25,965 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:25,967 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:25,968 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:25,969 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:25,970 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:29,265 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'2579'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2883'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999797'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b9119008f5e849e38478217ab1347b9a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cda86ddf2f182-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:29,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:29,555 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:29,561 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:29,564 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:29,569 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:29,575 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 16:28:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '2579', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2883', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999797', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b9119008f5e849e38478217ab1347b9a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986cda86ddf2f182-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 19:28:29,578 - openai._base_client - DEBUG - request_id: req_b9119008f5e849e38478217ab1347b9a\n",
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "2025-09-29 19:28:29,627 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-06b0f2aa-a171-458c-bca3-f96e9674e95a', 'json_data': {'messages': [{'content': \"I'm Peyman, 27, love coding and gaming\", 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_oMBBpxG56Yry0qF9FzkyQac6', 'function': {'name': 'UserProfile', 'arguments': '{\"name\": \"Peyman\", \"age\": 27, \"interests\": [\"coding\", \"gaming\"]}'}}]}, {'content': 'Error:\\n\\n```\\nUnable to serialize unknown type: <class \\'pydantic.fields.FieldInfo\\'>\\n```\\nExpected Parameter Schema:\\n\\n```json\\n{\\'properties\\': {\\'name\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \\'The name of the user.\\', \\'title\\': \\'Name\\'}, \\'age\\': {\\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \\'The age of the user.\\', \\'title\\': \\'Age\\'}, \\'gender\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'title\\': \\'Gender\\'}, \\'interests\\': {\\'anyOf\\': [{\\'items\\': {\\'type\\': \\'string\\'}, \\'type\\': \\'array\\'}, {\\'type\\': \\'null\\'}], \\'description\\': \"The user\\'s interests.\", \\'title\\': \\'Interests\\'}}, \\'title\\': \\'UserProfile\\', \\'type\\': \\'object\\'}\\n```\\nPlease use PatchFunctionErrors to fix all validation errors. for json_doc_id=[call_oMBBpxG56Yry0qF9FzkyQac6].', 'role': 'tool', 'tool_call_id': 'call_oMBBpxG56Yry0qF9FzkyQac6'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'PatchFunctionErrors', 'description': 'Respond with all JSONPatch operations required to update the previous invalid function call.\\n\\nUse to correct all validation errors in non-compliant function calls, or to extend or update existing structured data in the presence of new information. Closely analyze\\nthe parameters from the original JSONSchema to ensure the patched document will be valid\\nand that you avoid repeating the same errors.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the function you are patching.', 'type': 'string'}, 'planned_edits': {'description': 'Second, write a bullet-point list of each ValidationError you encountered and the corresponding JSONPatch operation needed to heal it. For each operation, write why your initial guess was incorrect,  citing the corresponding types(s) from the JSONSchema that will be used the validate the resultant patched document.  Think step-by-step to ensure no error is overlooked.', 'type': 'string'}, 'patches': {'description': \"Finally, provide a list of JSONPatch operations to be applied to the previous tool call's response arguments. If none are required, return an empty list. This field is REQUIRED. Multiple patches in the list are applied sequentially in the order provided, with each patch building upon the result of the previous one.\", 'items': {'description': \"A JSON Patch document represents an operation to be performed on a JSON document.\\n\\nNote that the op and path are ALWAYS required. Value is required for ALL operations except 'remove'.\", 'examples': [{'op': 'replace', 'path': '/path/to/my_array/1', 'value': 'the newer value to be patched'}, {'op': 'replace', 'path': '/path/to/broken_object', 'value': {'new': 'object'}}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['some', 'values']}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['newer']}, {'op': 'remove', 'path': '/path/to/my_array/1'}], 'properties': {'op': {'description': \"The operation to be performed. Must be one of 'add', 'remove', 'replace'.\", 'enum': ['add', 'remove', 'replace'], 'type': 'string'}, 'path': {'description': 'A JSON Pointer path that references a location within the target document where the operation is performed. Note: patches are applied sequentially. If you remove a value, the collection size changes before the next patch is applied.', 'type': 'string'}, 'value': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}], 'description': \"The value to be used within the operation. REQUIRED for 'add', 'replace', and 'test' operations. Pay close attention to the json schema to ensure patched document will be valid.\"}}, 'required': ['op', 'path', 'value'], 'type': 'object'}, 'type': 'array'}}, 'required': ['json_doc_id', 'planned_edits', 'patches'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'PatchFunctionName', 'description': 'Call this if the tool message indicates that you previously invoked an invalid tool, (e.g., \"Unrecognized tool name\" error), do so here.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the function you are patching.', 'type': 'string'}, 'reasoning': {'description': 'Seconds, provide at least 2 logical reasons why this action ought to be taken.Cite the specific error(s) mentioned to motivate the fix.', 'items': {'type': 'string'}, 'type': 'array'}, 'fixed_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Finally, if you need to change the name of the function (e.g., from an \"Unrecognized tool name\" error), do so here. Must be one of UserProfile'}}, 'required': ['json_doc_id', 'reasoning', 'fixed_name'], 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:29,630 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:29,631 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:29,638 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:29,639 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:29,643 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:29,644 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:32,560 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'2644'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2688'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999797'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8d514562133848b4af2616b3c7f51de8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cda9dddf1f182-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:32,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:32,628 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:32,643 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:32,650 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:32,668 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:32,685 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 16:28:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '2644', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2688', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999797', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8d514562133848b4af2616b3c7f51de8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986cda9dddf1f182-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 19:28:32,692 - openai._base_client - DEBUG - request_id: req_8d514562133848b4af2616b3c7f51de8\n",
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:39.090784Z",
     "start_time": "2025-09-29T16:28:39.088929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ],
   "id": "5bce2e7c4f08bd4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_oMBBpxG56Yry0qF9FzkyQac6)\n",
      " Call ID: call_oMBBpxG56Yry0qF9FzkyQac6\n",
      "  Args:\n",
      "    name: Peyman\n",
      "    age: 27\n",
      "    interests: ['coding', 'gaming']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:39.114995Z",
     "start_time": "2025-09-29T16:28:39.111868Z"
    }
   },
   "cell_type": "code",
   "source": "result[\"responses\"]",
   "id": "bb44bfa9338397cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(name='Peyman', age=27, gender=(FieldInfo(annotation=NoneType, required=False, default=None),), interests=['coding', 'gaming'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:39.139028Z",
     "start_time": "2025-09-29T16:28:39.133280Z"
    }
   },
   "cell_type": "code",
   "source": "result[\"responses\"][0].model_dump()",
   "id": "fae7dcea44ce3ff8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=(FieldInfo(annotation=Non...d=False, default=None),), input_type=tuple])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Peyman',\n",
       " 'age': 27,\n",
       " 'gender': (FieldInfo(annotation=NoneType, required=False, default=None),),\n",
       " 'interests': ['coding', 'gaming']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Partial Update with Trustcall",
   "id": "bae757f7c3ae1b60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:42.334200Z",
     "start_time": "2025-09-29T16:28:39.162240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "message = HumanMessage(content=\"Some times I also go finishing with my family\")\n",
    "updated_memory = extractor.invoke({\n",
    "    \"messages\": [message],\n",
    "    \"existing\": {\"UserProfile\": result[\"responses\"][0].model_dump()}\n",
    "})"
   ],
   "id": "2d042757024c043",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "2025-09-29 19:28:39,168 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7b8f7219-fa86-4f70-9440-cd16b7180626', 'json_data': {'messages': [{'content': 'Generate JSONPatches to update the existing schema instances.\\n<existing>\\n<schema id=UserProfile>\\n<instance>\\n{\\'name\\': \\'Peyman\\', \\'age\\': 27, \\'gender\\': (FieldInfo(annotation=NoneType, required=False, default=None),), \\'interests\\': [\\'coding\\', \\'gaming\\']}\\n</instance>\\n    <json_schema>\\n    {\\'properties\\': {\\'name\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'default\\': None, \\'description\\': \\'The name of the user.\\', \\'title\\': \\'Name\\'}, \\'age\\': {\\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}], \\'default\\': None, \\'description\\': \\'The age of the user.\\', \\'title\\': \\'Age\\'}, \\'gender\\': {\\'anyOf\\': [{\\'type\\': \\'string\\'}, {\\'type\\': \\'null\\'}], \\'title\\': \\'Gender\\'}, \\'interests\\': {\\'anyOf\\': [{\\'items\\': {\\'type\\': \\'string\\'}, \\'type\\': \\'array\\'}, {\\'type\\': \\'null\\'}], \\'default\\': None, \\'description\\': \"The user\\'s interests.\", \\'title\\': \\'Interests\\'}}, \\'title\\': \\'UserProfile\\', \\'type\\': \\'object\\'}\\n    </json_schema>\\n</schema>\\n</existing>\\n', 'role': 'system'}, {'content': 'Some times I also go finishing with my family', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': {'type': 'function', 'function': {'name': 'PatchDoc'}}, 'tools': [{'type': 'function', 'function': {'name': 'PatchDoc', 'description': 'Respond with JSONPatch operations to update the existing JSON document based on the provided text and schema.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the document you are patching.', 'type': 'string'}, 'planned_edits': {'description': \"Seconds, think step-by-step, reasoning over each required update and the corresponding JSONPatch operation to accomplish it. Cite the fields in the JSONSchema you referenced in developing this plan. Address each path as a group; don't switch between paths.\\n Plan your patches in the following order:1. replace - this keeps collection size the same.\\n2. remove - BE CAREFUL ABOUT ORDER OF OPERATIONS. Each operation is applied sequentially. For arrays, remove the highest indexed value first to avoid shifting indices. This ensures subsequent remove operations remain valid.\\n 3. add (for arrays, use /- to efficiently append to end).\", 'type': 'string'}, 'patches': {'description': \"Finally, provide a list of JSONPatch operations to be applied to the previous tool call's response arguments. If none are required, return an empty list. This field is REQUIRED. Multiple patches in the list are applied sequentially in the order provided, with each patch building upon the result of the previous one. Take care to respect array bounds. Order patches as follows:\\n 1. replace - this keeps collection size the same\\n 2. remove - BE CAREFUL about order of operations. For arrays, remove the highest indexed value first to avoid shifting indices.\\n 3. add - for arrays, use /- to efficiently append to end.\", 'items': {'description': \"A JSON Patch document represents an operation to be performed on a JSON document.\\n\\nNote that the op and path are ALWAYS required. Value is required for ALL operations except 'remove'.\", 'examples': [{'op': 'replace', 'path': '/path/to/my_array/1', 'value': 'the newer value to be patched'}, {'op': 'replace', 'path': '/path/to/broken_object', 'value': {'new': 'object'}}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['some', 'values']}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['newer']}, {'op': 'remove', 'path': '/path/to/my_array/1'}], 'properties': {'op': {'description': \"The operation to be performed. Must be one of 'add', 'remove', 'replace'.\", 'enum': ['add', 'remove', 'replace'], 'type': 'string'}, 'path': {'description': 'A JSON Pointer path that references a location within the target document where the operation is performed. Note: patches are applied sequentially. If you remove a value, the collection size changes before the next patch is applied.', 'type': 'string'}, 'value': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}], 'description': \"The value to be used within the operation. REQUIRED for 'add', 'replace', and 'test' operations. Pay close attention to the json schema to ensure patched document will be valid.\"}}, 'required': ['op', 'path', 'value'], 'type': 'object'}, 'type': 'array'}}, 'required': ['json_doc_id', 'planned_edits', 'patches'], 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:39,170 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:39,172 - httpcore.connection - DEBUG - close.started\n",
      "2025-09-29 19:28:39,173 - httpcore.connection - DEBUG - close.complete\n",
      "2025-09-29 19:28:39,173 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-09-29 19:28:39,182 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11be7e5a0>\n",
      "2025-09-29 19:28:39,182 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b2cb50> server_hostname='api.openai.com' timeout=None\n",
      "2025-09-29 19:28:39,195 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11bf5fd10>\n",
      "2025-09-29 19:28:39,195 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:39,196 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:39,196 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:39,198 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:39,198 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:42,290 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'2780'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2869'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999761'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8c216f112d5041148a3464b9743dd9da'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cdad98bfdb0d2-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:42,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:42,297 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:42,298 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:42,300 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:42,301 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:42,302 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 16:28:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '2780', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2869', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999761', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8c216f112d5041148a3464b9743dd9da', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986cdad98bfdb0d2-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 19:28:42,303 - openai._base_client - DEBUG - request_id: req_8c216f112d5041148a3464b9743dd9da\n",
      "/Users/peyman/Documents/github/llm-engineering-12-week-roadmap/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "2025-09-29 19:28:42,329 - extraction - ERROR - 1 validation error for UserProfile\n",
      "gender\n",
      "  Input should be a valid string [type=string_type, input_value=(FieldInfo(annotation=Non...d=False, default=None),), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:42.355413Z",
     "start_time": "2025-09-29T16:28:42.352941Z"
    }
   },
   "cell_type": "code",
   "source": "updated_memory[\"responses\"]",
   "id": "b246f55aad8187c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:42.361736Z",
     "start_time": "2025-09-29T16:28:42.360109Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "496845c4d5e2cdd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Memory Collection Schema\n",
    "\n",
    "Sometimes we want the memory to be a list of documents instead of a single document such as UserProfile."
   ],
   "id": "e9e1f82528b8d6f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:42.379456Z",
     "start_time": "2025-09-29T16:28:42.376829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ],
   "id": "e850b173025975e9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.189510Z",
     "start_time": "2025-09-29T16:28:42.395841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "trustcall_executor = create_extractor(\n",
    "    llm,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,  # Allow the extractor to insert new memories to the collection\n",
    ")\n",
    "\n",
    "prompt = \"Extract memories from the following conversation:\"\n",
    "\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Peyman.\"),\n",
    "                AIMessage(content=\"Nice to meet you, Peyman.\"),\n",
    "                HumanMessage(content=\"This morning I have started my new project with langgraph.\")]\n",
    "\n",
    "result = trustcall_executor.invoke({\"messages\": [SystemMessage(content=prompt)] + conversation})"
   ],
   "id": "1c4ce34b3bda837b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:28:42,415 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-3208a9ab-0afb-405f-93d4-777ebdb34e5a', 'json_data': {'messages': [{'content': 'Extract memories from the following conversation:', 'role': 'system'}, {'content': \"Hi, I'm Peyman.\", 'role': 'user'}, {'content': 'Nice to meet you, Peyman.', 'role': 'assistant'}, {'content': 'This morning I have started my new project with langgraph.', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Memory'}}, 'tools': [{'type': 'function', 'function': {'name': 'Memory', 'description': None, 'parameters': {'properties': {'content': {'description': 'The main content of the memory. For example: User expressed interest in learning about French.', 'title': 'Content', 'type': 'string'}}, 'required': ['content'], 'title': 'Memory', 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:42,417 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:42,418 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:42,419 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:42,420 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:42,421 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:42,421 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:43,173 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'500'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'547'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999958'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b9e58dd16a524e4ba54518a95543c595'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cdaedae74b0d2-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:43,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:43,175 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:43,180 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:43,181 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:43,181 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:43,183 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 16:28:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '500', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '547', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999958', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b9e58dd16a524e4ba54518a95543c595', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986cdaedae74b0d2-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 19:28:43,184 - openai._base_client - DEBUG - request_id: req_b9e58dd16a524e4ba54518a95543c595\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.198134Z",
     "start_time": "2025-09-29T16:28:43.195326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ],
   "id": "893da89fbd21d473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_5CPNwA5i0OvFmVtiXdX7x4Ln)\n",
      " Call ID: call_5CPNwA5i0OvFmVtiXdX7x4Ln\n",
      "  Args:\n",
      "    content: Peyman started a new project with langgraph this morning.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.219043Z",
     "start_time": "2025-09-29T16:28:43.216916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result[\"responses\"]:\n",
    "    print(msg)"
   ],
   "id": "87442d4009e345b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Peyman started a new project with langgraph this morning.'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.227537Z",
     "start_time": "2025-09-29T16:28:43.224953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result[\"response_metadata\"]:\n",
    "    print(msg)"
   ],
   "id": "9b3cb76eea8eba8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_5CPNwA5i0OvFmVtiXdX7x4Ln'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.243958Z",
     "start_time": "2025-09-29T16:28:43.241596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "updated_conversation = [AIMessage(content=\"That's great, tell me more about it?\"),\n",
    "                        HumanMessage(content=\"Actually it is a mobile app developed with Flutter, and backend is python.\"),\n",
    "                        AIMessage(content=\"Nice, What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking so I need to start designing the database schema and design entities and relationships.\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "tool_name = \"Memory\"\n",
    "existing_memory = []\n",
    "for index, content in enumerate(result[\"responses\"]):\n",
    "    existing_memory.append((str(index), \"Memory\", content))"
   ],
   "id": "bcc67397feae29ce",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:43.262002Z",
     "start_time": "2025-09-29T16:28:43.259668Z"
    }
   },
   "cell_type": "code",
   "source": "existing_memory",
   "id": "ccd8501ae8343129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  Memory(content='Peyman started a new project with langgraph this morning.'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:45.825802Z",
     "start_time": "2025-09-29T16:28:43.266506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_new = trustcall_executor.invoke({\n",
    "    \"messages\": [SystemMessage(content=system_msg)] + updated_conversation,\n",
    "    \"existing\": existing_memory\n",
    "})"
   ],
   "id": "c79f11e730c145c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:28:43,269 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-2748671b-2161-4396-a5f6-5605e0f36bf3', 'json_data': {'messages': [{'content': 'Update existing memories and create new ones based on the following conversation:\\n\\nGenerate JSONPatches to update the existing schema instances. If you need to extract or insert *new* instances of the schemas, call the relevant function(s).\\n<existing>\\n<instance id=0 schema_type=\"Memory\">\\n{\\'content\\': \\'Peyman started a new project with langgraph this morning.\\'}\\n</instance>\\n</existing>\\n', 'role': 'system'}, {'content': \"That's great, tell me more about it?\", 'role': 'assistant'}, {'content': 'Actually it is a mobile app developed with Flutter, and backend is python.', 'role': 'user'}, {'content': 'Nice, What else is on your mind?', 'role': 'assistant'}, {'content': 'I was thinking so I need to start designing the database schema and design entities and relationships.', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'PatchDoc', 'description': 'Respond with JSONPatch operations to update the existing JSON document based on the provided text and schema.', 'parameters': {'properties': {'json_doc_id': {'description': 'First, identify the json_doc_id of the document you are patching.', 'type': 'string'}, 'planned_edits': {'description': \"Seconds, think step-by-step, reasoning over each required update and the corresponding JSONPatch operation to accomplish it. Cite the fields in the JSONSchema you referenced in developing this plan. Address each path as a group; don't switch between paths.\\n Plan your patches in the following order:1. replace - this keeps collection size the same.\\n2. remove - BE CAREFUL ABOUT ORDER OF OPERATIONS. Each operation is applied sequentially. For arrays, remove the highest indexed value first to avoid shifting indices. This ensures subsequent remove operations remain valid.\\n 3. add (for arrays, use /- to efficiently append to end).\", 'type': 'string'}, 'patches': {'description': \"Finally, provide a list of JSONPatch operations to be applied to the previous tool call's response arguments. If none are required, return an empty list. This field is REQUIRED. Multiple patches in the list are applied sequentially in the order provided, with each patch building upon the result of the previous one. Take care to respect array bounds. Order patches as follows:\\n 1. replace - this keeps collection size the same\\n 2. remove - BE CAREFUL about order of operations. For arrays, remove the highest indexed value first to avoid shifting indices.\\n 3. add - for arrays, use /- to efficiently append to end.\", 'items': {'description': \"A JSON Patch document represents an operation to be performed on a JSON document.\\n\\nNote that the op and path are ALWAYS required. Value is required for ALL operations except 'remove'.\", 'examples': [{'op': 'replace', 'path': '/path/to/my_array/1', 'value': 'the newer value to be patched'}, {'op': 'replace', 'path': '/path/to/broken_object', 'value': {'new': 'object'}}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['some', 'values']}, {'op': 'add', 'path': '/path/to/my_array/-', 'value': ['newer']}, {'op': 'remove', 'path': '/path/to/my_array/1'}], 'properties': {'op': {'description': \"The operation to be performed. Must be one of 'add', 'remove', 'replace'.\", 'enum': ['add', 'remove', 'replace'], 'type': 'string'}, 'path': {'description': 'A JSON Pointer path that references a location within the target document where the operation is performed. Note: patches are applied sequentially. If you remove a value, the collection size changes before the next patch is applied.', 'type': 'string'}, 'value': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'array'}, {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'boolean'}, {'type': 'number'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}]}, 'type': 'object'}, {'type': 'null'}], 'description': \"The value to be used within the operation. REQUIRED for 'add', 'replace', and 'test' operations. Pay close attention to the json schema to ensure patched document will be valid.\"}}, 'required': ['op', 'path', 'value'], 'type': 'object'}, 'type': 'array'}}, 'required': ['json_doc_id', 'planned_edits', 'patches'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Memory', 'description': '', 'parameters': {'properties': {'content': {'description': 'The main content of the memory. For example: User expressed interest in learning about French.', 'type': 'string'}}, 'required': ['content'], 'type': 'object'}}}]}}\n",
      "2025-09-29 19:28:43,270 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-09-29 19:28:43,271 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:43,271 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-09-29 19:28:43,271 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:43,272 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-09-29 19:28:43,272 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:45,796 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 29 Sep 2025 16:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jcfkn8uqxwulfm4co4jmz4qq'), (b'openai-processing-ms', b'2098'), (b'openai-project', b'proj_VIxfUePeKPhJXr7DBQ8ClJDz'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2245'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29999836'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_9a12b20fb669433cb83ed18ae83cbac3'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'986cdaf2f8b1b0d2-IST'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-29 19:28:45,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 19:28:45,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-29 19:28:45,807 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-09-29 19:28:45,807 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-09-29 19:28:45,808 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-09-29 19:28:45,808 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 29 Sep 2025 16:28:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jcfkn8uqxwulfm4co4jmz4qq', 'openai-processing-ms': '2098', 'openai-project': 'proj_VIxfUePeKPhJXr7DBQ8ClJDz', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2245', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29999836', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_9a12b20fb669433cb83ed18ae83cbac3', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '986cdaf2f8b1b0d2-IST', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-29 19:28:45,808 - openai._base_client - DEBUG - request_id: req_9a12b20fb669433cb83ed18ae83cbac3\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:45.849993Z",
     "start_time": "2025-09-29T16:28:45.848272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for m in result_new[\"responses\"]:\n",
    "    print(m)"
   ],
   "id": "ddad9ac18959998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Peyman started a new project with langgraph this morning. The project is a mobile app developed with Flutter, and the backend is Python.'\n",
      "content='Peyman is thinking about designing the database schema and designing entities and relationships for the new project.'\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:45.865797Z",
     "start_time": "2025-09-29T16:28:45.862728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result_new[\"messages\"]:\n",
    "    msg.pretty_print()"
   ],
   "id": "f4759655c2fc31ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_rfQb3AMle8ZYBDcsEmP30loj)\n",
      " Call ID: call_rfQb3AMle8ZYBDcsEmP30loj\n",
      "  Args:\n",
      "    content: Peyman started a new project with langgraph this morning. The project is a mobile app developed with Flutter, and the backend is Python.\n",
      "  Memory (call_afO64ITnGQXAMgCNKinhcEhj)\n",
      " Call ID: call_afO64ITnGQXAMgCNKinhcEhj\n",
      "  Args:\n",
      "    content: Peyman is thinking about designing the database schema and designing entities and relationships for the new project.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:45.875468Z",
     "start_time": "2025-09-29T16:28:45.873407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for msg in result_new[\"response_metadata\"]:\n",
    "    print(msg)"
   ],
   "id": "1f70e75ea35bd919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_rfQb3AMle8ZYBDcsEmP30loj', 'json_doc_id': '0'}\n",
      "{'id': 'call_afO64ITnGQXAMgCNKinhcEhj'}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:35:53.765490Z",
     "start_time": "2025-09-29T16:35:53.754086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "existing_memory = [(str(index), \"Memory\", memory.model_dump()) for index, memory in enumerate(result_new[\"responses\"])]\n",
    "\n",
    "existing_memory"
   ],
   "id": "c872fc37466ca1d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Peyman started a new project with langgraph this morning. The project is a mobile app developed with Flutter, and the backend is Python.'}),\n",
       " ('1',\n",
       "  'Memory',\n",
       "  {'content': 'Peyman is thinking about designing the database schema and designing entities and relationships for the new project.'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:28:45.908216Z",
     "start_time": "2025-09-29T16:28:45.906871Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e0769ae47c8da01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
